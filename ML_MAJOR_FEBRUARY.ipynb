{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset \n",
    "data = pd.read_csv('./Data_cardiovascular_risk.csv')\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will drop `education` and `id` columns because it has nothing to do with heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','education'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to convert all the string values into int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "df['is_smoking'] = df['is_smoking'].apply(lambda x: 1 if x == 'YES' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_smoking'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize missing values by using missingno library\n",
    "import missingno as msno\n",
    "\n",
    "# Visualize missing values as a matrix\n",
    "msno.matrix(df,figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation between the number of missing values in different columns as a heatmap\n",
    "msno.heatmap(df,figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# % of Missing data in each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent_total = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)*100\n",
    "missing = pd.concat([total, percent_total], axis=1, keys=[\"Total\", \"Percentage\"])\n",
    "missingdf = missing[missing['Total']>0]\n",
    "print(missingdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the % of Missing data in each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=missingdf.index, y=missingdf['Percentage'], data = missingdf)\n",
    "plt.title('Percentage of missing data by feature')\n",
    "plt.xlabel('Features', fontsize=14)\n",
    "plt.ylabel('Percentage', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Count the rows which have missing data and get % out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in df.isnull().sum(axis=1):\n",
    "    if i>0:\n",
    "        count=count+1\n",
    "print('Total number of rows with missing values is ', count)\n",
    "# checking missing value percentage \n",
    "print(\"% of rows which have missing data: \",round((count/len(df.index))*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we can drop the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)\n",
    "\n",
    "# checking if there are any missing values left\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Checking for Any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Statistics of dataset after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.gca()\n",
    "df.hist(ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plotting pie chart for TenYearCHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "df['TenYearCHD'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('TenYearCHD')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot(x='TenYearCHD', data=df, ax=ax[1])\n",
    "ax[1].set_title('TenYearCHD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's Visualize the target and age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('No. of people with and without cardiovascular disease')\n",
    "sns.countplot(x='age',hue= 'TenYearCHD' ,data=df, palette='colorblind', edgecolor=sns.color_palette('dark', n_colors=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* People with `Highest risk` of developing heart disease are between `51 - 63`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variable Comparisions with Target Variable - `TenYearCHD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **Stacked Bar Chart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def stacked_barchart(data, title = None, ylabel = None, xlabel = None):\n",
    "  # Function to plot stacked bar chart\n",
    "    default_colors = ['#006400', '#FF0000', '#228B22']\n",
    "    # From raw value to percentage\n",
    "    totals = data.sum(axis=1)\n",
    "    bars = ((data.T / totals) * 100).T\n",
    "    r = list(range(data.index.size))\n",
    "\n",
    "    #Plot\n",
    "    barWidth = 0.85\n",
    "    names = data.index.tolist()\n",
    "    bottom = [0] * bars.shape[0]\n",
    "\n",
    "    # Create bars\n",
    "    color_index = 0\n",
    "    plots = []\n",
    "    for bar in bars.columns:\n",
    "        plots.append(plt.bar(r, bars[bar], bottom=bottom, color=default_colors[color_index], edgecolor='white', width=barWidth))\n",
    "        bottom = list(map(add, bottom, bars[bar]))\n",
    "        color_index = 0 if color_index >= len(default_colors) else color_index + 1\n",
    "\n",
    "    # Custom x axis\n",
    "    plt.title(title)\n",
    "    plt.xticks(r, names)\n",
    "    plt.xlabel(data.index.name if xlabel is None else xlabel)\n",
    "    plt.ylabel(data.columns.name if ylabel is None else ylabel)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    y_labels = ax.get_yticks()\n",
    "    ax.set_yticklabels([str(y) + '%' for y in y_labels])\n",
    "\n",
    "    flat_list = [item for sublist in data.T.values for item in sublist]\n",
    "    for i, d in zip(ax.patches, flat_list):\n",
    "        data_label = str(d) + \" (\" + str(round(i.get_height(), 2)) + \"%)\"\n",
    "        ax.text(i.get_x() + 0.45, i.get_y() + 5 , data_label, ha='center', va='bottom', fontdict=dict(color='black', size=20))\n",
    "\n",
    "    for item in ([ax.title]):\n",
    "        item.set_fontsize(27)\n",
    "    \n",
    "    for item in ([ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(24)\n",
    "\n",
    "    legend = ax.legend(plots, bars.columns.tolist(), ncol=2, fancybox=True)\n",
    "    plt.setp(legend.get_texts(), fontsize='20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's Visualize each category with respect to Target Vsriable - TenYearCHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualzing each category with respect to target variable\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(27, 35)\n",
    "grid_rows = 3\n",
    "grid_cols = 2\n",
    "\n",
    "#Plot sex vs disease outcome\n",
    "plt.subplot(grid_rows, grid_cols, 1)\n",
    "temp = df[['sex','TenYearCHD']].groupby(['sex','TenYearCHD']).size().unstack('TenYearCHD')\n",
    "temp.rename(index={0:'Female', 1:'Male'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\n",
    "stacked_barchart(temp, title = 'Cardiovascular heart disease vs Sex', ylabel = 'Population')\n",
    "\n",
    "#Plot smoking satus vs disease outcome\n",
    "plt.subplot(grid_rows, grid_cols, 2)\n",
    "temp = df[['is_smoking','TenYearCHD']].groupby(['is_smoking','TenYearCHD']).size().unstack('TenYearCHD')\n",
    "temp.rename(index={0:'Not a Smoker', 1:'Smoker'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\n",
    "stacked_barchart(temp, title = 'Cardiovascular heart disease vs Smoking', ylabel = 'Population')\n",
    "\n",
    "#Plot diabetes vs disease outcome\n",
    "plt.subplot(grid_rows, grid_cols, 3)\n",
    "temp = df[['diabetes','TenYearCHD']].groupby(['diabetes','TenYearCHD']).size().unstack('TenYearCHD')\n",
    "temp.rename(index={0:'Not Diabetic', 1:'Diabetic'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\n",
    "stacked_barchart(temp, title = 'Cardiovascular heart disease vs Diabetes', ylabel = 'Population')\n",
    "\n",
    "#Plot BP meds vs disease outcome\n",
    "plt.subplot(grid_rows, grid_cols, 4)\n",
    "temp = df[['BPMeds','TenYearCHD']].groupby(['BPMeds','TenYearCHD']).size().unstack('TenYearCHD')\n",
    "temp.rename(index={0:'Not on medication', 1:'On Medication'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\n",
    "stacked_barchart(temp, title = 'Cardiovascular heart disease vs BP meds', ylabel = 'Population')\n",
    "\n",
    "#Plot Hypertension vs disease outcome\n",
    "plt.subplot(grid_rows, grid_cols, 5)\n",
    "temp = df[['prevalentHyp','TenYearCHD']].groupby(['prevalentHyp','TenYearCHD']).size().unstack('TenYearCHD')\n",
    "temp.rename(index={0:'Not Hypertensive', 1:'Hypertensive'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\n",
    "stacked_barchart(temp, title = 'Cardiovascular heart disease vs Hypertension', ylabel = 'Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above categorical variables comparison plot we can conclude that,\n",
    "\n",
    "*   Slightly more males are suffering from Cardiovascular heart disease than females.\n",
    "*   The people who have Cardiovascular heart disease is almost equal between smokers and non smokers.\n",
    "*   The percentage of people who have Cardiovascular heart disease is higher among the diabetic patients and also those patients with prevalent hypertension have more risk of Cardiovascular heart disease compare to those who don't have hypertensive problem.\n",
    "*   The percentage of people who are on medication of blood pressure have more risk of Cardiovascular heart disease compare to those who are not on medication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see the Correlation between the all features using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "correlation = df.corr()\n",
    "sns.heatmap(abs(correlation), annot = True, cmap='YlGnBu')\n",
    "plt.title('Correlation between the all features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above correlation plot we can conclude that**,\n",
    "\n",
    "*   There are no features with more than 0.2 correlation with the Ten year risk of developing CHD and this shows that the features a poor predictors. However the features with the highest correlations are age, prevalent hypertension(prevalentHyp) and systolic blood pressure(sysBP).\n",
    "\n",
    "*   Also there are a couple of features that are highly correlated with each other and it makes no sense to use both of them in building a machine learning model. \n",
    "\n",
    "**These includes:** \n",
    "\n",
    "*  Blood glucose and diabetes;\n",
    "*  systolic and diastolic blood pressures;\n",
    "*  cigarette smoking and the number of cigarretes smoked per day. \n",
    "\n",
    "Therefore we need to carry out feature selection to pick the best features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree-based: SelectFromModel**\n",
    "\n",
    "**SelectFromModel** is an Embedded method. Embedded methods use algorithms that have built-in feature selection methods.\n",
    "\n",
    "Here,\n",
    "\n",
    "We have used RandomForest() to select features based on feature importance.\n",
    "We calculate feature importance using node impurities in each decision tree. \n",
    "\n",
    "In Random forest, the final feature importance is the average of all decision tree feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features\n",
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define SelectFromModel feature selection method\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=14)\n",
    "embeded_rf_selector.fit(x, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = x.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important or Top Features\n",
    "embeded_rf_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Statistics on Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Splitting the dependent and independent vatriables\n",
    "top_features = df[embeded_rf_feature]\n",
    "y = df['TenYearCHD']\n",
    "\n",
    "result = sm.Logit(y, top_features).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Checking the `odds radio` of `top features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['Odds Ratio'] = params\n",
    "conf.columns = ['5%', '95%', 'Odds Ratio']\n",
    "print(np.exp(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Getting `Cardiovacular Heart disease` risk increases with about `2%` for every increase in `age` and `sysBP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = 'TenYearCHD', markers=[\"o\", \"s\"], vars = embeded_rf_feature, palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Predicting with ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE** algorithm works in 4 simple steps:\n",
    "\n",
    "* Choose a minority class as the input vector\n",
    "* Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n",
    "* Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n",
    "* Repeat the steps until data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X = df[embeded_rf_feature]\n",
    "y = df.iloc[:,-1]\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print('Original dataset shape', len(df))\n",
    "print('Resampled dataset shape', len(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "labels = [\"Negative Cases\",\"Positive Cases\"]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x=labels, y=list(dict(Counter(y)).values()))\n",
    "plt.title(\"Numbers Before Balancing\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(x=labels,y= list(dict(Counter(y_smote)).values()))\n",
    "plt.title(\"Numbers After Balancing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data to Training and Testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create our new dataset\n",
    "\n",
    "df_new = pd.concat([pd.DataFrame(x_smote), pd.DataFrame(y_smote)], axis=1)\n",
    "df_new.columns = ['age', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose','TenYearCHD']\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = df_new[embeded_rf_feature]\n",
    "y_new = df_new[\"TenYearCHD\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x_new,y_new,test_size=0.2,random_state=42)\n",
    "print(\"Training features have {0} records and Testing features have {1} records.\".\\\n",
    "      format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Required Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score,precision_score,classification_report,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using gridsearch for optimum parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'penalty':['l1','l2'],\n",
    "         'C' : [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100,1e-3,1e+4,1e+5,1e+6],\n",
    "         'class_weight':['balanced',None]}\n",
    "logistic_clf = GridSearchCV(LogisticRegression(),param_grid=params,cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_clf.fit(X_train,Y_train)\n",
    "\n",
    "logistic_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_predict = logistic_clf.predict(X_test)\n",
    "logistic_accuracy = accuracy_score(Y_test,logistic_predict)\n",
    "print(f\"Using logistic regression we get an accuracy of {round(logistic_accuracy*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train ROC-AUC score : ', logistic_clf.best_estimator_.score(X_train,Y_train))\n",
    "print('Test ROC-AUC score : ', logistic_clf.best_estimator_.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Consfusion Matrix for `Logistic Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test,logistic_predict)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,logistic_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "probs = logistic_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "log_auc = roc_auc_score(Y_test, probs)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, probs)\n",
    "# plot curve\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title(f\"AUC = {round(log_auc,3)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using gridsearch for Optimum Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [40, 50],\n",
    "    'min_samples_split': [50, 100, 150],\n",
    "    'n_estimators': [50, 80, 100]\n",
    "  }\n",
    "\n",
    "random_clf = GridSearchCV(RandomForestClassifier(),param_grid=params_rf,cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Training the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf.fit(X_train,Y_train)\n",
    "\n",
    "random_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_predict = random_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accuracy = accuracy_score(Y_test,random_predict)\n",
    "print(f\"Using Random Forest we get an accuracy of {round(random_accuracy*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Confusion Matrix for `Random Forest Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test,random_predict)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,random_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC \n",
    "probs1 = random_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs1 = probs1[:, 1]\n",
    "# calculate AUC\n",
    "ran_auc = roc_auc_score(Y_test, probs1)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, probs1)\n",
    "# plot curve\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title(f\"AUC = {round(ran_auc,3)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using gridSearch for optimum Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'max_depth': range (2, 12, 1),\n",
    "    'n_estimators': range(60, 220, 20),\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "  }\n",
    "\n",
    "xgb_clf = GridSearchCV(XGBClassifier(), param_grid = params_xgb, cv = 10, scoring='roc_auc')\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train,Y_train)\n",
    "\n",
    "xgb_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict = xgb_clf.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(Y_test,xgb_predict)\n",
    "print(f\"Using XG boost we get an accuracy of {round(xgb_accuracy*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Confusion Matrix for XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test,xgb_predict)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, xgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC \n",
    "probs2 = xgb_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs2 = probs2[:, 1]\n",
    "# calculate AUC\n",
    "xgb_auc = roc_auc_score(Y_test, probs2)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, probs2)\n",
    "# plot curve\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title(f\"AUC = {round(xgb_auc,3)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using GridSearch for Optimum Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "svm_clf = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf1 = svm_clf.fit(X_train,Y_train)\n",
    "\n",
    "svm_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_accuracy = accuracy_score(Y_test,svm_predict)\n",
    "print(f\"Using Support Vector Machine we get an accuracy of {round(svm_accuracy*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test,svm_predict)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, svm_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC \n",
    "probs3 = svm_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs3 = probs3[:, 1]\n",
    "# calculate AUC\n",
    "svc_auc = roc_auc_score(Y_test, probs3)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, probs3)\n",
    "# plot curve\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title(f\"AUC = {round(svc_auc,3)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing All the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance_df = pd.DataFrame({\n",
    "    \"Logistic regression\":{'Test Accuracy':round(logistic_accuracy, 2),'Precision': round(precision_score(Y_test, logistic_predict), 2),'Recall': round(recall_score(Y_test, logistic_predict), 2),'F1 Score': round(f1_score(Y_test, logistic_predict), 2), 'AUC':round(log_auc, 2)},\n",
    "    \"Random Forest\":{'Test Accuracy':round(random_accuracy, 2),'Precision': round(precision_score(Y_test, random_predict), 2),'Recall': round(recall_score(Y_test, random_predict), 2),'F1 Score': round(f1_score(Y_test, random_predict), 2), 'AUC':round(ran_auc, 2)},\n",
    "    \"XG Boost\":{'Test Accuracy':round(xgb_accuracy, 2),'Precision': round(precision_score(Y_test, xgb_predict), 2),'Recall': round(recall_score(Y_test, xgb_predict), 2),'F1 Score': round(f1_score(Y_test, xgb_predict), 2), 'AUC':round(xgb_auc, 2)},\n",
    "    \"Support vector machine\":{'Test Accuracy':round(svm_accuracy, 2),'Precision': round(precision_score(Y_test, svm_predict), 2),'Recall': round(recall_score(Y_test, svm_predict), 2),'F1 Score': round(f1_score(Y_test, svm_predict), 2), 'AUC':round(svc_auc, 2)}\n",
    "}).T\n",
    "Performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since, **Support Vector Machine model** gives highest F score and AUC score. we will save this model to predict the disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's plot the accuracy and AUC score of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing accuracies of each algorithm in a list\n",
    "scores = [logistic_accuracy,random_accuracy,xgb_accuracy,svm_accuracy]\n",
    "# Naming the algorithms and storing in a list\n",
    "algorithms = [\"Logistic Regression\",\"Random Forest\",\"XG Boost\",\"Support vector machine\"] \n",
    "# Visualize the algorithms\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "sns.barplot(x=algorithms,y=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing AUC score of each algorithm in a list\n",
    "auc_scores = [log_auc,ran_auc,xgb_auc,svc_auc]\n",
    "# Naming the algorithms and storing in a list\n",
    "algorithms = [\"Logistic Regression\",\"Random Forest\",\"XG Boost\",\"Support vector machine\"] \n",
    "# Visualize the algorithms\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"AUC score\")\n",
    "sns.barplot(x=algorithms,y=auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From both the graphs we can say that the best performing model is **Support Vector Machine** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion:**\n",
    "* The people who have Cardiovascular heart disease is almost equal between smokers and non smokers.\n",
    "* The top features in predicting the ten year risk of developing Cardiovasular Heart Disease are **'age', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose'**.\n",
    "* The Support vector machine with the radial kernel is the best performing model in terms of accuracy and the F1 score and Its high AUC-score shows that it has a high true positive rate.\n",
    "* Balancing the dataset by using the SMOTE technique helped in improving the models' sensitivity.\n",
    "* With more data(especially that of the minority class) better models can be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let us save the `Support Vector Machine` model to use it furthur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svm_clf1,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
